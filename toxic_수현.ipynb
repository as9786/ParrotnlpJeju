{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "toxic_수현.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "EljQDJE1AXC5"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/as9786/ParrotnlpJeju/blob/main/toxic_%EC%88%98%ED%98%84.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcmFq__ZqzZG",
        "outputId": "ab35f409-e63a-45d7-cd9d-3b9b5f90e94a"
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True) \n",
        "import tensorflow as tf\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize #word:don't->do, n't // Jone's->Jone, 's #sent:여러개의 문장들->문장 구분\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Embedding, Input, LSTM, Bidirectional, GlobalMaxPool1D, Dropout, GRU\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKtwDdhsLsbb"
      },
      "source": [
        "## 1.데이터 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzilPVriBRHj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a767a199-474d-4067-f157-de1fad58eda9"
      },
      "source": [
        "train = pd.read_csv(\"/content/drive/MyDrive/2021-1 parrot project/TOXIC P/dataset_toxic/train.csv\")\n",
        "columns = list(train.columns)\n",
        "columns = columns[2:]\n",
        "columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "bGVn4vZwrNcQ",
        "outputId": "d9a9de86-5eee-456b-9aae-09cbeb428b8b"
      },
      "source": [
        "train.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000997932d777bf</td>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000103f0d9cfb60f</td>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000113f07ec002fd</td>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0001b41b1c6bb37e</td>\n",
              "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0001d958c54c6e35</td>\n",
              "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>00025465d4725e87</td>\n",
              "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0002bcb3da6cb337</td>\n",
              "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>00031b1e95af7921</td>\n",
              "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>00037261f536c51d</td>\n",
              "      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>00040093b2687caa</td>\n",
              "      <td>alignment on this subject and which are contra...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id  ... identity_hate\n",
              "0  0000997932d777bf  ...             0\n",
              "1  000103f0d9cfb60f  ...             0\n",
              "2  000113f07ec002fd  ...             0\n",
              "3  0001b41b1c6bb37e  ...             0\n",
              "4  0001d958c54c6e35  ...             0\n",
              "5  00025465d4725e87  ...             0\n",
              "6  0002bcb3da6cb337  ...             0\n",
              "7  00031b1e95af7921  ...             0\n",
              "8  00037261f536c51d  ...             0\n",
              "9  00040093b2687caa  ...             0\n",
              "\n",
              "[10 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "Bqs_Bu0SBkTf",
        "outputId": "550ffe06-345f-4d7d-f726-2e5a9490a6e0"
      },
      "source": [
        "train.loc[train[\"toxic\"]==1].head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0002bcb3da6cb337</td>\n",
              "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0005c987bdfc9d4b</td>\n",
              "      <td>Hey... what is it..\\n@ | talk .\\nWhat is it......</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0007e25b2121310b</td>\n",
              "      <td>Bye! \\n\\nDon't look, come or think of comming ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>001810bf8c45bf5f</td>\n",
              "      <td>You are gay or antisemmitian? \\n\\nArchangel WH...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>00190820581d90ce</td>\n",
              "      <td>FUCK YOUR FILTHY MOTHER IN THE ASS, DRY!</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  id  ... identity_hate\n",
              "6   0002bcb3da6cb337  ...             0\n",
              "12  0005c987bdfc9d4b  ...             0\n",
              "16  0007e25b2121310b  ...             0\n",
              "42  001810bf8c45bf5f  ...             1\n",
              "43  00190820581d90ce  ...             0\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "sqsf65cZBptU",
        "outputId": "55ecb946-9f1f-44b9-b446-e60c376b1ad7"
      },
      "source": [
        "sample_submission = pd.read_csv(\"/content/drive/MyDrive/2021-1 parrot project/TOXIC P/dataset_toxic/sample_submission.csv\")\n",
        "sample_submission.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00001cee341fdb12</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0000247867823ef7</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00013b17ad220c46</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00017563c3f7919a</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00017695ad8997eb</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id  toxic  severe_toxic  ...  threat  insult  identity_hate\n",
              "0  00001cee341fdb12    0.5           0.5  ...     0.5     0.5            0.5\n",
              "1  0000247867823ef7    0.5           0.5  ...     0.5     0.5            0.5\n",
              "2  00013b17ad220c46    0.5           0.5  ...     0.5     0.5            0.5\n",
              "3  00017563c3f7919a    0.5           0.5  ...     0.5     0.5            0.5\n",
              "4  00017695ad8997eb    0.5           0.5  ...     0.5     0.5            0.5\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "lScitMy9B59m",
        "outputId": "cd833c5f-a206-4365-8260-e430882549ef"
      },
      "source": [
        "test = pd.read_csv(\"/content/drive/MyDrive/2021-1 parrot project/TOXIC P/dataset_toxic/test.csv\")\n",
        "test.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00001cee341fdb12</td>\n",
              "      <td>Yo bitch Ja Rule is more succesful then you'll...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0000247867823ef7</td>\n",
              "      <td>== From RfC == \\n\\n The title is fine as it is...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00013b17ad220c46</td>\n",
              "      <td>\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00017563c3f7919a</td>\n",
              "      <td>:If you have a look back at the source, the in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00017695ad8997eb</td>\n",
              "      <td>I don't anonymously edit articles at all.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id                                       comment_text\n",
              "0  00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...\n",
              "1  0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...\n",
              "2  00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...\n",
              "3  00017563c3f7919a  :If you have a look back at the source, the in...\n",
              "4  00017695ad8997eb          I don't anonymously edit articles at all."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "nbGhADi_CBR6",
        "outputId": "01d2d4f7-9c59-473c-a094-1c701252aef4"
      },
      "source": [
        "test_labels = pd.read_csv(\"/content/drive/MyDrive/2021-1 parrot project/TOXIC P/dataset_toxic/test_labels.csv\")\n",
        "test_labels.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00001cee341fdb12</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0000247867823ef7</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00013b17ad220c46</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00017563c3f7919a</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00017695ad8997eb</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id  toxic  severe_toxic  ...  threat  insult  identity_hate\n",
              "0  00001cee341fdb12     -1            -1  ...      -1      -1             -1\n",
              "1  0000247867823ef7     -1            -1  ...      -1      -1             -1\n",
              "2  00013b17ad220c46     -1            -1  ...      -1      -1             -1\n",
              "3  00017563c3f7919a     -1            -1  ...      -1      -1             -1\n",
              "4  00017695ad8997eb     -1            -1  ...      -1      -1             -1\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJbXPz0v-S8n"
      },
      "source": [
        "# 2.EDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oni5o8GUyl7w",
        "outputId": "eb1b30bb-58bd-430a-e69a-ff48e1d1b890"
      },
      "source": [
        "print('훈련용 리뷰 개수 :',len(train)) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "훈련용 리뷰 개수 : 159571\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Xolz_tsbP-q"
      },
      "source": [
        "X_train = train.comment_text\n",
        "y_train = train[[\"toxic\",\t\"severe_toxic\",\t\"obscene\",\t\"threat\",\t\"insult\",\t\"identity_hate\"]].values\n",
        "X_test = test.comment_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6NuBYExbQwL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a576872-33e7-42a0-83b5-f5aedc568dee"
      },
      "source": [
        "y_train[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wf4IPMLVbSh3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d9e1627-bbd5-49c5-ca98-b4ed51aec1db"
      },
      "source": [
        "X_train.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    Explanation\\nWhy the edits made under my usern...\n",
              "1    D'aww! He matches this background colour I'm s...\n",
              "2    Hey man, I'm really not trying to edit war. It...\n",
              "3    \"\\nMore\\nI can't make any real suggestions on ...\n",
              "4    You, sir, are my hero. Any chance you remember...\n",
              "Name: comment_text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtQwtYp_bWG6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a6c0b45-85f4-478b-ad95-fe85c8666094"
      },
      "source": [
        "print('toxic: %d' % train[train['toxic'] > 0]['toxic'].count())\n",
        "print('severe_toxic: %d' % train[train['severe_toxic'] > 0]['severe_toxic'].count())\n",
        "print('obscene: %d' % train[train['obscene'] > 0]['obscene'].count())\n",
        "print('threat: %d' % train[train['threat'] > 0]['threat'].count())\n",
        "print('insult: %d' % train[train['insult'] > 0]['insult'].count())\n",
        "print('identity_hate: %d' % train[train['identity_hate'] > 0]['identity_hate'].count())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "toxic: 15294\n",
            "severe_toxic: 1595\n",
            "obscene: 8449\n",
            "threat: 478\n",
            "insult: 7877\n",
            "identity_hate: 1405\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sN-zcZ4EcdMg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d50d1737-f5de-4983-a5ec-e45401118cd3"
      },
      "source": [
        "train['len'] = train['comment_text'].str.len()\n",
        "print('Average comment length: %d' % train['len'].mean())\n",
        "print('Median comment length: %d' % train['len'].quantile(.5))\n",
        "print('90th percentile comment length: %d' % train['len'].quantile(.9))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average comment length: 394\n",
            "Median comment length: 205\n",
            "90th percentile comment length: 889\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dktWYVJbYF6"
      },
      "source": [
        "# 3.Preprocessing(토큰화, 정제, 정규화, 불용어 제거)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZjodz3ty1vR",
        "outputId": "11cf00b7-e244-4ffa-bebd-d4350ec0dd03"
      },
      "source": [
        "#데이터 중복 확인\n",
        "train['comment_text'].nunique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "159571"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qh1ax8h8zpty",
        "outputId": "b54fd3a0-0aff-4701-cff4-46c6506f7b82"
      },
      "source": [
        "#Null 값 확인\n",
        "print(train.isnull().values.any())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3u6akaHh4E7A"
      },
      "source": [
        "#기존 preprocessing\n",
        "\n",
        "def text_to_words(raw_text, remove_stopwords=False):\n",
        "    # 1. Remove non-letters, but including numbers\n",
        "    letters_only = re.sub(\"[^0-9a-zA-Z]\", \" \", raw_text)\n",
        "    \n",
        "\n",
        "    # 2. Convert to lower case, split into individual words\n",
        "    words = letters_only.lower().split()\n",
        "    if remove_stopwords:\n",
        "        stops = set(stopwords.words(\"english\")) # In Python, searching a set is much faster than searching\n",
        "        meaningful_words = [w for w in words if not w in stops] # Remove stop words\n",
        "        words = meaningful_words\n",
        "    return words \n",
        "\n",
        "sentences_train = train['comment_text'].apply(text_to_words, remove_stopwords=False)\n",
        "sentences_test = test['comment_text'].apply(text_to_words, remove_stopwords=False)\n",
        "\n",
        "print(sentences_train[:20])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oV7cPbl6tnZe",
        "outputId": "4ecd8cb7-8be1-4c1b-ba23-ad3f504957b8"
      },
      "source": [
        "#preprocessing\n",
        "\n",
        "def text_to_words(raw_text, remove_stopwords=False):\n",
        "    # 1. Remove non-letters, but including numbers\n",
        "    letters_only = re.sub(\"[^0-9a-zA-Z]\", \" \", raw_text) #영어, 숫자만\n",
        "    short=re.sub(r'\\W*\\b\\w{1,2}\\b',\" \",letters_only) #불필요한(의미없는) 단어 제거(1~2길이 단어 제거)\n",
        "    \n",
        "\n",
        "    # 2. Convert to lower case, split into individual words\n",
        "    words = short.lower().split() \n",
        "    if remove_stopwords:\n",
        "        stops = set(stopwords.words(\"english\")) # In Python, searching a set is much faster than searching\n",
        "        meaningful_words = [w for w in words if not w in stops] # 불용어 제거\n",
        "        words = meaningful_words\n",
        "    return words \n",
        "\n",
        "X_train = train['comment_text'].apply(text_to_words, remove_stopwords=False)\n",
        "X_test = test['comment_text'].apply(text_to_words, remove_stopwords=False)\n",
        "\n",
        "print(X_train[:20])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0     [explanation, why, the, edits, made, under, us...\n",
            "1     [aww, matches, this, background, colour, seemi...\n",
            "2     [hey, man, really, not, trying, edit, war, jus...\n",
            "3     [more, can, make, any, real, suggestions, impr...\n",
            "4     [you, sir, are, hero, any, chance, you, rememb...\n",
            "5     [congratulations, from, well, use, the, tools,...\n",
            "6         [cocksucker, before, you, piss, around, work]\n",
            "7     [your, vandalism, the, matt, shirvington, arti...\n",
            "8     [sorry, the, word, nonsense, was, offensive, y...\n",
            "9     [alignment, this, subject, and, which, are, co...\n",
            "10    [fair, use, rationale, for, image, wonju, jpg,...\n",
            "11    [bbq, man, and, lets, discuss, maybe, over, th...\n",
            "12    [hey, what, talk, what, exclusive, group, some...\n",
            "13    [before, you, start, throwing, accusations, an...\n",
            "14    [and, the, girl, above, started, her, argument...\n",
            "15    [juelz, santanas, age, 2002, juelz, santana, w...\n",
            "16    [bye, don, look, come, think, comming, back, t...\n",
            "17    [redirect, talk, voydan, pop, georgiev, cherno...\n",
            "18    [the, mitsurugi, point, made, sense, why, not,...\n",
            "19    [don, mean, bother, you, see, that, you, writi...\n",
            "Name: comment_text, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0grOYKo7Q8H"
      },
      "source": [
        "#정수 인코딩\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBwGzUZW8n-w",
        "outputId": "bc8118a3-622d-469c-916c-ab4a09d03345"
      },
      "source": [
        "print(tokenizer.word_index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQdv0lUq9Cfg",
        "outputId": "05bbb8f2-dce6-40de-9bab-d57d1ea91bae"
      },
      "source": [
        "# 빈도수가 낮은 단어들은 자연어 처리에서 배제\n",
        "threshold = 3\n",
        "total_cnt = len(tokenizer.word_index) # 단어의 수\n",
        "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
        "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
        "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
        "\n",
        "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
        "for key, value in tokenizer.word_counts.items():\n",
        "    total_freq = total_freq + value\n",
        "\n",
        "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
        "    if(value < threshold):\n",
        "        rare_cnt = rare_cnt + 1\n",
        "        rare_freq = rare_freq + value\n",
        "\n",
        "print('단어 집합(vocabulary)의 크기 :',total_cnt)\n",
        "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
        "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
        "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "단어 집합(vocabulary)의 크기 : 181189\n",
            "등장 빈도가 2번 이하인 희귀 단어의 수: 119936\n",
            "단어 집합에서 희귀 단어의 비율: 66.19386386590797\n",
            "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 1.742837666898735\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g92QvKX59lVm",
        "outputId": "8e58702a-0f45-4744-e0b2-2d06b6aad931"
      },
      "source": [
        "# 전체 단어 개수 중 빈도수 2이하인 단어는 제거.\n",
        "# 0번 패딩 토큰을 고려하여 + 1\n",
        "vocab_size = total_cnt - rare_cnt + 1\n",
        "print('단어 집합의 크기 :',vocab_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "단어 집합의 크기 : 61254\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-uZfgu_h8ojS"
      },
      "source": [
        "#텍스트 시퀀스를 숫자 시퀀스로 변환\n",
        "tokenizer = Tokenizer(vocab_size) \n",
        "tokenizer.fit_on_texts(X_train)\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_test = tokenizer.texts_to_sequences(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUo9D66H-Gnd",
        "outputId": "41aeaa05-2b1a-498b-a325-5d2d78bd5cfa"
      },
      "source": [
        "print(X_train[:3])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[617, 51, 1, 99, 102, 145, 607, 4240, 10989, 1000, 60, 290, 27, 2076, 10990, 31, 6553, 38, 2557, 119, 2734, 91, 1096, 14608, 2603, 2, 26, 36, 206, 1, 319, 17, 1, 19, 16, 115, 3152, 63, 4306], [15839, 2443, 6, 499, 3558, 4291, 2521, 11, 68, 19, 894, 7874, 149], [362, 372, 106, 7, 212, 50, 270, 31, 4, 6, 539, 2115, 440, 451, 76, 2, 547, 284, 99, 318, 19, 16, 176, 384, 37, 20, 1, 2211, 67, 1, 664, 416]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRTLPIBn_E9T"
      },
      "source": [
        "y_train = np.array(y_train)\n",
        "#y_test = np.array()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqrS-Jcp_OQi"
      },
      "source": [
        "#빈 샘플 제거\n",
        "drop_train = [index for index, sentence in enumerate(X_test) if len(sentence) < 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9BfrVoN_Xu8"
      },
      "source": [
        "# 빈 샘플들을 제거(없음)\n",
        "X_train = np.delete(X_train, drop_train, axis=0)\n",
        "#y_train = np.delete(y_train, drop_train, axis=0)\n",
        "print(len(X_train))\n",
        "#print(len(y_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "UkXyTxL-AFIR",
        "outputId": "c61d0b7e-94c3-4350-a8fa-03844eeda841"
      },
      "source": [
        "#패딩\n",
        "print('comment_text의 최대 길이 :',max(len(l) for l in X_train))\n",
        "print('commnet_text의 평균 길이 :',sum(map(len, X_train))/len(X_train))\n",
        "plt.hist([len(s) for s in X_train], bins=50)\n",
        "plt.xlabel('length of samples')\n",
        "plt.ylabel('number of samples')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "comment_text의 최대 길이 : 1250\n",
            "commnet_text의 평균 길이 : 51.64301157478489\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVGWH2iyAZn4"
      },
      "source": [
        "def below_threshold_len(max_len, nested_list):\n",
        "  cnt = 0\n",
        "  for s in nested_list:\n",
        "    if(len(s) <= max_len):\n",
        "        cnt = cnt + 1\n",
        "  print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (cnt / len(nested_list))*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_k5psXm5AsSr",
        "outputId": "efb951aa-bf29-4dc9-8aba-10c82df137f2"
      },
      "source": [
        "max_len = 150\n",
        "below_threshold_len(max_len, X_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "전체 샘플 중 길이가 150 이하인 샘플의 비율: 93.36972256863716\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hw14hXRvA-ri"
      },
      "source": [
        "#모든 샘플의 길이를 150으로 맞춤\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "X_train = pad_sequences(X_train, maxlen = max_len)\n",
        "X_test = pad_sequences(X_test, maxlen = max_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1z8XVdnhB9K2",
        "outputId": "6f76b795-e4dc-4225-9ad3-acfe23b624bc"
      },
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(159571, 150)\n",
            "(153164, 150)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvFj-f2pFWAo"
      },
      "source": [
        "num_words = 20000\n",
        "max_len = 150\n",
        "emb_size = 128"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwyzcLHQBk_e"
      },
      "source": [
        "from tensorflow.keras.layers import Embedding, Dense, LSTM\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1A-rq56tFLsA",
        "outputId": "0bebaa20-949e-432b-eeba-f19d3f09cb31"
      },
      "source": [
        "input = Input(shape = (max_len,))\n",
        "layer = Embedding(num_words,emb_size)(input) #num_words의 단어를 emb_size로 벡터화\n",
        "layer = Bidirectional(LSTM(50,return_sequences=True,recurrent_dropout=0.15))(layer) #return_sequences : 레이어를 여러 개 쌓아 올릴 때\n",
        "# recurrent_dropout : 현재 Input에 영향을 받는 Parameter에만 Dropout을 적용하는 것\n",
        "layer = GlobalMaxPool1D()(layer)\n",
        "layer = Dropout(0.2)(layer)\n",
        "layer = Dense(50,activation = 'relu')(layer)\n",
        "layer = Dropout(0.2)(layer)\n",
        "layer = Dense(6,activation = 'sigmoid')(layer)\n",
        "model = Model(inputs = input, outputs=layer)\n",
        "model.compile(loss = 'binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 150)]             0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, 150, 128)          2560000   \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 150, 100)          71600     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d (Global (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 50)                5050      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 6)                 306       \n",
            "=================================================================\n",
            "Total params: 2,636,956\n",
            "Trainable params: 2,636,956\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xV3fB4iUFifL"
      },
      "source": [
        "file_path = '{epoch:02d}-{val_loss:.5f}.h5'\n",
        "checkpoint = ModelCheckpoint(file_path,monitor='val_loss',verbose = 1, save_best_only=True)\n",
        "early_stop = EarlyStopping(monitor='val_loss',patience=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xuI5FkCc4Rrp",
        "outputId": "493606bc-3c53-40dc-b60c-dbe1ac9429a6"
      },
      "source": [
        "#preprocessing 2\n",
        "def text_to_words(raw_text):\n",
        "    # 1. Remove non-letters, but including numbers\n",
        "    raw_text = re.sub(\"[^0-9a-zA-Z]\", \" \", raw_text) #영어, 숫자만\n",
        "    raw_text = re.sub(r'\\W*\\b\\w{1,2}\\b',\" \",raw_text) #불필요한(의미없는) 단어 제거(1~2길이 단어 제거)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yv4v1Mdu4_gQ",
        "outputId": "cb91853a-043f-4520-b610-676864b686ef"
      },
      "source": [
        "from nltk.corpus import stopwords  \n",
        "nltk.download('stopwords')\n",
        "stop_words = stopwords.words('english')\n",
        "print(stop_words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "Pq3DMWAw40r1",
        "outputId": "4687ce36-174e-487c-f47d-a1e79e25ab79"
      },
      "source": [
        "# 토큰화 #불용어 제거\n",
        "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
        "\n",
        "X_train = []\n",
        "for sentence in train['comment_text']:\n",
        "    temp_X = text_to_word_sequence(temp_X) # 토큰화\n",
        "    temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
        "    X_train.append(temp_X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-3bd33e66c178>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'comment_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mtemp_X\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtemp_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_to_word_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_X\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 토큰화\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m    988\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/range.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m    356\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'comment_text'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKxI2u623oNC"
      },
      "source": [
        "X_train = \n",
        "y_train = \n",
        "X_test = test.comment_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJsSQZXt8Wkb"
      },
      "source": [
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "stop = stopwords.words('english')\n",
        "\n",
        "train['preprocess'] = train.apply(lambda row: row['comment_text'].replace(\"\\n\",\" \"), axis=1) #removes new line character\n",
        "test['preprocess'] = test.apply(lambda row: row['comment_text'].replace(\"\\n\",\" \"), axis=1)\n",
        "\n",
        "#removes urls\n",
        "train['preprocess']=train.apply(lambda row: re.sub('http://\\S+|https://\\S+', 'urls',row['preprocess']).lower(), axis=1)\n",
        "test['preprocess']=test.apply(lambda row: re.sub('http://\\S+|https://\\S+', 'urls',row['preprocess']).lower(), axis=1)\n",
        "\n",
        "#remove all non-alphanumeric values(Except single quotes)\n",
        "train['preprocess']=train.apply(lambda row: re.sub('[^A-Za-z\\' ]+', '',row['preprocess']).lower(), axis=1)\n",
        "test['preprocess']=test.apply(lambda row: re.sub('[^A-Za-z\\' ]+', '',row['preprocess']).lower(), axis=1)\n",
        "\n",
        "#remove stopwords as they occupy major chunk of the vocabulary\n",
        "train['preprocess'] = train['preprocess'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
        "test['preprocess'] = test['preprocess'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
        "\n",
        "#removes all additional spaces\n",
        "train['preprocess']=train.apply(lambda row: re.sub('  +', ' ',row['preprocess']).strip(), axis=1)\n",
        "test['preprocess']=test.apply(lambda row: re.sub('  +', ' ',row['preprocess']).strip(), axis=1)\n",
        "#https://www.kaggle.com/sasidharturaga/eda-step-wise-preprocess-and-lstm-classifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3f5zNX2pAHzC"
      },
      "source": [
        "# 3.W2V"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61pI3xnja5c9"
      },
      "source": [
        "Word2Vec 모델 1(model)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcJAYURB0mi3"
      },
      "source": [
        "from gensim.models import word2vec\n",
        "num_features = 300    # Word vector dimensionality                      \n",
        "min_word_count = 40   # Minimum word count                        \n",
        "num_workers = 4       # Number of threads to run in parallel\n",
        "context = 10          # Context window size                                                                                    \n",
        "downsampling = 1e-3   # Downsample setting for frequent words\n",
        "# Initialize and train the model \n",
        "model = word2vec.Word2Vec(sentences_train, workers=num_workers, size=num_features, min_count = min_word_count, window = context, sample = downsampling)\n",
        "model.init_sims(replace=True) # marks the end of training to speed up the use of the model(필요없는 메모리 unload)\n",
        "#model = gensim.models.Word2Vec(iter=1, min_count=5)\n",
        "#size = 워드 벡터의 특징 값. 즉, 임베딩 된 벡터의 차원.\n",
        "#window = 컨텍스트 윈도우 크기\n",
        "#min_count = 단어 최소 빈도 수 제한 (빈도가 적은 단어들은 학습하지 않는다.)\n",
        "#workers = 학습을 위한 프로세스 수\n",
        "#sg = 0은 CBOW, 1은 Skip-gram."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkKe14ypdsdV"
      },
      "source": [
        "vectors = model.wv\n",
        "#del model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBUYWeRidtKU",
        "outputId": "08fde001-7a82-46ea-e94b-68b743b13ddc"
      },
      "source": [
        "vectors['good']\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 4.05162983e-02, -8.71024802e-02, -7.61475191e-02,  4.17969637e-02,\n",
              "       -2.51455661e-02,  5.37620299e-02, -7.50558004e-02,  3.74311432e-02,\n",
              "       -3.64701822e-02,  4.41822596e-02,  5.03319576e-02, -1.80146173e-02,\n",
              "       -2.47544236e-02,  1.78050734e-02, -1.49769075e-02, -5.42766042e-02,\n",
              "        4.15359624e-02, -5.26966807e-03, -7.32954592e-03, -4.98701073e-02,\n",
              "       -8.09885841e-03,  3.94709148e-02, -4.15089540e-02, -6.69024047e-03,\n",
              "        2.32009552e-02,  5.40364683e-02, -5.51157212e-03,  6.84705451e-02,\n",
              "       -9.22702998e-02, -1.18233517e-01, -6.29208535e-02, -8.41974374e-03,\n",
              "       -2.39799600e-02, -3.51625457e-02,  1.56299230e-02,  9.94248874e-03,\n",
              "        1.18854344e-01,  1.00253923e-02,  1.37081698e-01,  5.03376424e-02,\n",
              "        6.01260439e-02,  1.60821155e-01,  4.99149822e-02,  1.16240596e-02,\n",
              "        7.73984566e-02, -1.12584131e-02, -3.99333760e-02,  1.83403715e-02,\n",
              "       -1.26908785e-02,  1.86943896e-02,  2.72952691e-02, -5.61766420e-03,\n",
              "       -7.96805099e-02, -2.77512968e-02, -4.23389534e-03, -8.21707621e-02,\n",
              "        1.71409659e-02, -2.72265100e-03,  1.38031080e-01, -6.90698950e-03,\n",
              "       -3.03695519e-02,  9.91249681e-02,  2.89626420e-03, -1.70932140e-03,\n",
              "       -4.86160256e-02, -1.89705361e-02,  7.34929089e-03,  1.04474854e-02,\n",
              "        4.97688837e-02,  2.46845484e-02, -2.51319390e-02, -7.50344992e-02,\n",
              "        7.55027533e-02, -2.54432624e-03, -9.30966064e-02,  8.99204537e-02,\n",
              "        6.77850097e-03,  1.72419176e-02,  1.03582963e-01,  7.79406801e-02,\n",
              "       -2.07685120e-02, -3.04802554e-03, -3.93775813e-02, -1.60891205e-01,\n",
              "       -4.50870357e-02,  5.75345755e-02, -2.53645051e-02, -2.52148286e-02,\n",
              "        3.40687782e-02,  1.88597420e-03,  7.32112397e-03,  8.51890258e-03,\n",
              "       -1.69474240e-02, -3.81483771e-02, -4.48042154e-02,  5.16448580e-02,\n",
              "       -1.08794779e-01, -7.37414882e-02, -3.99510115e-02,  1.51338279e-02,\n",
              "       -1.24568380e-01, -5.34958094e-02,  3.84167321e-02, -3.69063541e-02,\n",
              "        2.87373662e-02, -4.67470940e-03,  9.15649161e-02,  8.93919244e-02,\n",
              "       -3.50812823e-02, -9.46594693e-04,  7.27510825e-02, -9.21713002e-03,\n",
              "        5.32846376e-02, -7.28764981e-02,  1.59739535e-02, -4.47088964e-02,\n",
              "       -1.01525053e-01, -6.73112348e-02,  1.14171635e-02,  6.17658682e-02,\n",
              "       -2.29807384e-02,  3.60666104e-02, -6.36247993e-02,  6.57532737e-02,\n",
              "       -9.09841247e-03, -1.01661243e-01, -1.11693189e-01,  2.95910798e-02,\n",
              "       -1.72551554e-02,  5.21173030e-02,  3.07247490e-02,  6.59819171e-02,\n",
              "        9.32085980e-03, -1.44783929e-02,  6.70223460e-02, -7.93107897e-02,\n",
              "       -5.48986457e-02, -1.44008705e-02, -1.62927192e-02,  5.38003296e-02,\n",
              "        1.09167434e-02, -1.33046150e-01, -1.40942847e-02,  1.21042337e-02,\n",
              "       -7.56798014e-02,  5.01552671e-02,  1.74539424e-02,  1.14988117e-02,\n",
              "        6.18743338e-03, -1.53139336e-02, -1.16575472e-01,  8.28849599e-02,\n",
              "       -7.44670630e-02,  1.63209923e-02, -9.19978246e-02,  8.00685510e-02,\n",
              "        3.87898237e-02,  5.79860210e-02, -3.63268256e-02, -2.76476648e-02,\n",
              "       -9.36222449e-02, -1.28614577e-02,  5.59291653e-02, -3.68867069e-02,\n",
              "        5.22091277e-02,  1.25734955e-01, -9.04278606e-02, -1.00340217e-01,\n",
              "       -9.23005715e-02,  4.85462137e-02, -5.14313520e-04, -5.27157485e-02,\n",
              "        4.75785397e-02, -4.76254076e-02, -6.64984882e-02, -5.19877039e-02,\n",
              "       -8.94172788e-02, -1.89999044e-02, -9.36431736e-02, -6.46713898e-02,\n",
              "       -2.80766096e-02, -3.87677550e-02, -1.20205082e-01, -5.12307994e-02,\n",
              "       -5.30627891e-02,  9.98234004e-02, -1.92276333e-02, -1.00826770e-02,\n",
              "       -5.60279982e-03, -1.67093612e-02, -2.72200294e-02,  6.24299943e-02,\n",
              "       -9.66635793e-02, -4.92651351e-02, -8.25526044e-02,  1.62519142e-03,\n",
              "        1.14778504e-02, -1.40219450e-03, -5.31435870e-02, -1.97290685e-02,\n",
              "        1.36204530e-02,  1.24918759e-01,  1.93676504e-03, -9.69134364e-03,\n",
              "        5.54465838e-02,  3.07731610e-02, -4.45686467e-03,  7.60580152e-02,\n",
              "       -2.57945526e-02,  2.42972150e-02,  7.98955336e-02,  3.59134702e-03,\n",
              "       -1.19089680e-02,  1.20745162e-02,  1.05712973e-01,  5.61722293e-02,\n",
              "       -1.59748904e-02,  5.27611971e-02, -1.09368507e-02, -1.64989606e-02,\n",
              "        7.33932033e-02, -6.58241734e-02,  7.27088004e-02, -1.11521734e-02,\n",
              "       -2.98194140e-02, -4.02923338e-02, -1.14308514e-01, -4.18723859e-02,\n",
              "        1.21270902e-01,  7.09158406e-02,  8.95718765e-03, -8.34472179e-02,\n",
              "        1.00372136e-01,  2.14492204e-03, -2.68134568e-03, -1.12181798e-01,\n",
              "       -5.81749268e-02,  1.00421928e-01, -8.19066167e-02,  7.77424723e-02,\n",
              "        2.25194748e-02,  2.09816676e-02,  4.56574224e-02,  1.34768024e-01,\n",
              "       -2.60092062e-03,  5.47984801e-02, -5.80246709e-02,  2.20623706e-02,\n",
              "        4.53520045e-02, -7.43408548e-03, -2.34286282e-02, -4.10716273e-02,\n",
              "       -4.39115465e-02,  1.64419934e-02, -4.96016406e-02, -2.59241704e-02,\n",
              "        2.17107311e-02,  2.37647779e-02, -1.31535843e-01, -2.44987085e-02,\n",
              "       -7.21470863e-02, -3.81681882e-02,  3.23802861e-03, -1.12455105e-02,\n",
              "       -1.58299692e-02, -4.66429740e-02,  6.77796751e-02, -1.13533763e-02,\n",
              "        3.98083851e-02, -3.45756859e-02,  2.63986774e-02, -1.11785112e-02,\n",
              "        3.79241705e-02, -7.65957087e-02, -2.84291198e-03,  1.16394356e-01,\n",
              "        3.79697271e-02, -2.60513388e-02, -9.86275971e-02, -1.60342455e-02,\n",
              "       -2.86546554e-02, -2.12628059e-02, -8.59859884e-02,  3.40197347e-02,\n",
              "       -3.59549671e-02, -9.90693516e-05, -5.87536544e-02, -3.43197063e-02,\n",
              "        6.23953082e-02, -2.94090025e-02, -3.91554348e-02, -9.07860473e-02,\n",
              "       -2.22785063e-02, -4.36098613e-02,  9.08030197e-02, -2.40767021e-02,\n",
              "        5.20984456e-02,  6.68866560e-03,  1.35381566e-02,  8.36651698e-02],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4eRKQvUHVuc",
        "outputId": "8c92ad00-89b9-4f31-8409-ebe54cae8e66"
      },
      "source": [
        "model_result1 = model.wv.most_similar(\"good\")\n",
        "print(model_result1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('bad', 0.705236554145813), ('nice', 0.524634063243866), ('great', 0.43744146823883057), ('terrible', 0.4244636595249176), ('poor', 0.41128724813461304), ('fine', 0.40439271926879883), ('better', 0.39479655027389526), ('decent', 0.35686445236206055), ('useful', 0.3566397726535797), ('helpful', 0.35612648725509644)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFrq6jj_9C-A",
        "outputId": "767e0165-3d21-48fe-c93e-da5f781f3f56"
      },
      "source": [
        "model.wv.vectors.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11250, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThQHUICZ9I9Y",
        "outputId": "310ae2ae-7800-4783-955b-94199d85360e"
      },
      "source": [
        "embedding_matrix_w2vc = np.zeros((vocab_size, 300))\n",
        "np.shape(embedding_matrix_w2vc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(190060, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SI-M0g5n9fx1"
      },
      "source": [
        "def get_vector(word):\n",
        "    if word in model.wv:\n",
        "        return model.wv[word]\n",
        "    else:\n",
        "        return None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "tIG_-6JN9kwD",
        "outputId": "bcde14b2-a95f-43f7-ba1b-837770560159"
      },
      "source": [
        "for word, i in tokenizer.word_index.items():\n",
        "    temp = get_vector(word)  # 훈련 데이터의 단어 집합에서 단어와 정수 인덱스를 1개씩 꺼내온다.\n",
        "    if temp is not None : # 만약 None이 아니라면 임베딩 벡터의 값을 리턴받은 것이므로\n",
        "        embedding_matrix_w2vc[i] = temp"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-b6cf2c51ac11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 훈련 데이터의 단어 집합에서 단어와 정수 인덱스를 1개씩 꺼내온다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtemp\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;31m# 만약 None이 아니라면 임베딩 벡터의 값을 리턴받은 것이므로\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0membedding_matrix_w2vc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLfNjVVO1q3I",
        "outputId": "c6001b09-375f-48ca-d005-78ba6ac3b516"
      },
      "source": [
        "model_result2 = model.wv.most_similar(\"war\")\n",
        "print(model_result2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('wars', 0.704084038734436), ('warring', 0.5758286714553833), ('warred', 0.5712268352508545), ('battle', 0.5578720569610596), ('invasion', 0.5347889065742493), ('wwii', 0.5132366418838501), ('victory', 0.4959246516227722), ('iraq', 0.48020192980766296), ('army', 0.4778652787208557), ('conflicts', 0.4700937867164612)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I43uvYasHYLq",
        "outputId": "834aa289-be65-457b-f0b8-272482c99ae2"
      },
      "source": [
        "model_result3 = model.wv.most_similar(\"fuck\")\n",
        "print(model_result3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('cunt', 0.6021218299865723), ('fucking', 0.5642269849777222), ('fuckin', 0.5507758855819702), ('bitch', 0.5249624252319336), ('shit', 0.5185149908065796), ('motherfucker', 0.5167473554611206), ('hell', 0.5121530294418335), ('ass', 0.5093834400177002), ('damn', 0.5087145566940308), ('shitty', 0.4960164725780487)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SsWUhyhwrgG1",
        "outputId": "5bd36c43-229d-46a1-e311-c901535044b3"
      },
      "source": [
        "model_result4 = model.wv.most_similar(\"explanation\")\n",
        "print(model_result4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('justification', 0.6364733576774597), ('rationale', 0.5308720469474792), ('reason', 0.49440914392471313), ('indication', 0.47945696115493774), ('outline', 0.4675516188144684), ('objection', 0.46657252311706543), ('argument', 0.4611869752407074), ('reasoning', 0.43700283765792847), ('reasons', 0.43660852313041687), ('context', 0.4362267553806305)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5dOw71XYh1U"
      },
      "source": [
        "from gensim.models import KeyedVectors\n",
        "model.wv.save_word2vec_format('eng_w2v') # 모델 저장\n",
        "#loaded_model = KeyedVectors.load_word2vec_format(\"eng_w2v\") # 모델 로드"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfHZj060bJJd"
      },
      "source": [
        "loaded_model = KeyedVectors.load_word2vec_format(\"eng_w2v\") # 모델 로드"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3pPL6vrVbLsp",
        "outputId": "3b888e02-fd90-4616-8840-b10057e8836a"
      },
      "source": [
        "model_result5 = loaded_model.most_similar(\"war\")\n",
        "print(model_result5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('wars', 0.6803454160690308), ('warring', 0.5769931077957153), ('battle', 0.5550742745399475), ('warred', 0.5338819026947021), ('invasion', 0.5066319108009338), ('victory', 0.4874706268310547), ('army', 0.4848262071609497), ('wwii', 0.4671473503112793), ('soviet', 0.45776572823524475), ('iraq', 0.4575268030166626)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ch8DLdlTIdLt"
      },
      "source": [
        "embedding vector to model?(https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/) 방법 찾기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euFaJZsIJ5fu"
      },
      "source": [
        "import numpy as np\n",
        "import gensim\n",
        "word2vec_model = gensim.models.KeyedVectors.load_word2vec_format('eng_w2v', binary=True)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DE0NXmlJIHRz",
        "outputId": "f2175162-0ff4-41c9-8f24-3dc908b203c5"
      },
      "source": [
        "print(word2vec_model.vectors.shape)# 모델의 크기 확인"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8165, 300)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1jhcuczIkuJ"
      },
      "source": [
        "#300의 차원을 가진 Word2Vec 벡터가 8210개 있음..?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iP9a8PVlUSgk",
        "outputId": "cd55a58e-6284-48b4-ac24-190501ed90cc"
      },
      "source": [
        "vocab_size=len(sentences_train)\n",
        "vocab_size"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "159571"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8kb3hJyxaZcV",
        "outputId": "a0c1344b-cac5-48c3-de8e-ac966d038acc"
      },
      "source": [
        "embedding_matrix = np.zeros((vocab_size, 300))\n",
        "# 단어 집합 크기의 행과 300개의 열을 가지는 행렬 생성. 값은 전부 0으로 채워진다.\n",
        "np.shape(embedding_matrix)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(159571, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkgMvG51abCf"
      },
      "source": [
        "def get_vector(word):\n",
        "    if word in word2vec_model:\n",
        "        return word2vec_model[word]\n",
        "    else:\n",
        "        return None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7XNu5rZaj9K"
      },
      "source": [
        "for word, i in sentences_train.items(): # 훈련 데이터의 단어 집합에서 단어와 정수 인덱스를 1개씩 꺼내온다.\n",
        "    temp = get_vector(word) # 단어(key) 해당되는 임베딩 벡터의 300개의 값(value)를 임시 변수에 저장\n",
        "    if temp is not None: # 만약 None이 아니라면 임베딩 벡터의 값을 리턴받은 것이므로\n",
        "        embedding_matrix[i] = temp # 해당 단어 위치의 행에 벡터의 값을 저장한다."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ud80wdQTSe4Y"
      },
      "source": [
        "# create a weight matrix for words in training docs\n",
        "embedding_matrix = zeros((vocab_size, 100))\n",
        "for word, i in t.word_index.items():\n",
        "\tembedding_vector = embeddings_index.get(word)\n",
        "\tif embedding_vector is not None:\n",
        "\t\tembedding_matrix[i] = embedding_vector\n",
        "# define model\n",
        "model = Sequential()\n",
        "e = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=4, trainable=False)\n",
        "model.add(e)\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "# compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "# summarize the model\n",
        "print(model.summary())\n",
        "# fit the model\n",
        "model.fit(padded_docs, labels, epochs=50, verbose=0)\n",
        "# evaluate the model\n",
        "loss, accuracy = model.evaluate(padded_docs, labels, verbose=0)\n",
        "print('Accuracy: %f' % (accuracy*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrkkQd4rVI84"
      },
      "source": [
        "Embedding Layer 방법 찾기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mdqqManVJVX"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, Flatten\n",
        "max_len=150\n",
        "model = Sequential()\n",
        "e = Embedding(vocab_size, 300, weights=[embedding_matrix], input_length=max_len, trainable=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "mO2CcycrVV_I",
        "outputId": "3d1999a5-0f73-45c5-9e30-1cf7efbbfac2"
      },
      "source": [
        "model.add(e)\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
        "model.fit(X_train, y_train, epochs=100, verbose=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-77-a72c46000280>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    206\u001b[0m           \u001b[0;31m# and create the node connecting the current layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m           \u001b[0;31m# to the input layer we just created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m           \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m           \u001b[0mset_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0;32m--> 952\u001b[0;31m                                                 input_list)\n\u001b[0m\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;31m# Maintains info about the `Layer.call` stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1089\u001b[0m         \u001b[0;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m         outputs = self._keras_tensor_symbolic_call(\n\u001b[0;32m-> 1091\u001b[0;31m             inputs, input_masks, args, kwargs)\n\u001b[0m\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    860\u001b[0m           \u001b[0;31m# overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m           \u001b[0;31m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2720\u001b[0m           \u001b[0;31m# Using `init_scope` since we want variable assignment in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2721\u001b[0m           \u001b[0;31m# `set_weights` to be treated like variable initialization.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2722\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2723\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2724\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36mset_weights\u001b[0;34m(self, weights)\u001b[0m\n\u001b[1;32m   1871\u001b[0m           raise ValueError(\n\u001b[1;32m   1872\u001b[0m               \u001b[0;34m'Layer weight shape %s not compatible with provided weight '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1873\u001b[0;31m               'shape %s' % (ref_shape, weight.shape))\n\u001b[0m\u001b[1;32m   1874\u001b[0m         \u001b[0mweight_value_tuples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1875\u001b[0m         \u001b[0mweight_index\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Layer weight shape (159571, 300) not compatible with provided weight shape (159570, 300)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhORA5K22UAo"
      },
      "source": [
        "from gensim.models import KeyedVectors\n",
        "model.wv.save_word2vec_format('eng_w2v') # 모델 저장\n",
        "loaded_model = KeyedVectors.load_word2vec_format(\"eng_w2v\") # 모델 로드"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzER_ko92e5t",
        "outputId": "8b74cd2e-2f64-46da-ac39-0dd358af9534"
      },
      "source": [
        "model_result5 = loaded_model.most_similar(\"war\")\n",
        "print(model_result5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('wars', 0.7109693288803101), ('warring', 0.5761391520500183), ('battle', 0.5750802159309387), ('warred', 0.5735384225845337), ('victory', 0.5078235864639282), ('army', 0.5007004737854004), ('wwii', 0.4778203070163727), ('invasion', 0.4759833514690399), ('iraq', 0.472567081451416), ('warrior', 0.461758553981781)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95zuHKv1G9xY",
        "outputId": "3412fc8d-dbef-4f71-9473-a35fbb7edd19"
      },
      "source": [
        "model.similarity('sock', 'toxic')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.0068683233"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gTN99E9a1Qi"
      },
      "source": [
        "Word2Vec 모델 2(model2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ATr3YaFHbvG"
      },
      "source": [
        "from gensim.models import word2vec\n",
        "num_features = 300    # Word vector dimensionality                      \n",
        "min_word_count = 40   # Minimum word count                        \n",
        "num_workers = 4       # Number of threads to run in parallel\n",
        "context = 10          # Context window size                                                                                    \n",
        "downsampling = 1e-3   # Downsample setting for frequent words\n",
        "# Initialize and train the model (this will take some time)\n",
        "model2 = word2vec.Word2Vec(sentences_train, size=100, window=5, min_count=5, workers=4, sg=1)\n",
        "model2.init_sims(replace=True) # marks the end of training to speed up the use of the model(필요없는 메모리 unload)\n",
        "#model = gensim.models.Word2Vec(iter=1, min_count=5)\n",
        "#size = 워드 벡터의 특징 값. 즉, 임베딩 된 벡터의 차원.\n",
        "#window = 컨텍스트 윈도우 크기\n",
        "#min_count = 단어 최소 빈도 수 제한 (빈도가 적은 단어들은 학습하지 않는다.)\n",
        "#workers = 학습을 위한 프로세스 수\n",
        "#sg = 0은 CBOW, 1은 Skip-gram."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "On_XoHDTHfQu",
        "outputId": "48b6ae2a-d0c5-4fd3-d2c1-aaff076c440e"
      },
      "source": [
        "model2_result6 = model2.wv.most_similar(\"good\")\n",
        "print(model2_result6)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('nice', 0.7333452105522156), ('bad', 0.7260962724685669), ('superb', 0.6809818148612976), ('faith', 0.679627537727356), ('brilliant', 0.6740128993988037), ('luck', 0.6657828092575073), ('decent', 0.6600880026817322), ('fantastic', 0.6519118547439575), ('swell', 0.646277904510498), ('natured', 0.6327653527259827)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7yUoBTXHhFg",
        "outputId": "0f9267a8-d5c7-47cf-a8ea-616172f82f9c"
      },
      "source": [
        "model2_result7 = model2.wv.most_similar(\"war\")\n",
        "print(model2_result7)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('wars', 0.7387489676475525), ('wwii', 0.6697685718536377), ('punic', 0.6681240200996399), ('falklands', 0.6664019823074341), ('waging', 0.6646537780761719), ('napoleonic', 0.6543854475021362), ('1812', 0.6528611183166504), ('battle', 0.6519602537155151), ('sparked', 0.6470191478729248), ('wwi', 0.6465203762054443)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5dnSf11HhMD",
        "outputId": "9bcd0baa-a1f3-4777-bfb8-1aa8ed788d9f"
      },
      "source": [
        "model2_result8 = model2.wv.most_similar(\"fuck\")\n",
        "print(model2_result8)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('supressing', 0.7694493532180786), ('facists', 0.7684067487716675), ('misterwiki', 0.7493607997894287), ('niggas', 0.7447677254676819), ('fuk', 0.7409355044364929), ('bitches', 0.7389950752258301), ('suk', 0.73809415102005), ('sod', 0.7254297137260437), ('shitty', 0.7244499921798706), ('fcuk', 0.7225721478462219)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GtXvt7-Jgxl"
      },
      "source": [
        "from gensim.models import KeyedVectors\n",
        "model2.wv.save_word2vec_format('eng2_w2v') # 모델 저장\n",
        "loaded_model2 = KeyedVectors.load_word2vec_format(\"eng2_w2v\") # 모델 로드"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSIyrJh4a-iN"
      },
      "source": [
        "Word2Vec 모델 3(model3)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_7-qvxyHxxi"
      },
      "source": [
        "from gensim.models import word2vec\n",
        "num_features = 300    # Word vector dimensionality                      \n",
        "min_word_count = 40   # Minimum word count                        \n",
        "num_workers = 4       # Number of threads to run in parallel\n",
        "context = 10          # Context window size                                                                                    \n",
        "downsampling = 1e-3   # Downsample setting for frequent words\n",
        "# Initialize and train the model (this will take some time)\n",
        "model3 = word2vec.Word2Vec(sentences_train, size=100, window=5, min_count=5, workers=4, sg=0)\n",
        "model3.init_sims(replace=True) # marks the end of training to speed up the use of the model(필요없는 메모리 unload)\n",
        "#model = gensim.models.Word2Vec(iter=1, min_count=5)\n",
        "#size = 워드 벡터의 특징 값. 즉, 임베딩 된 벡터의 차원.\n",
        "#window = 컨텍스트 윈도우 크기\n",
        "#min_count = 단어 최소 빈도 수 제한 (빈도가 적은 단어들은 학습하지 않는다.)\n",
        "#workers = 학습을 위한 프로세스 수\n",
        "#sg = 0은 CBOW, 1은 Skip-gram."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jqTTcoCI-T3",
        "outputId": "f2898b80-6782-44ef-cb31-1eecbda5b810"
      },
      "source": [
        "model3_result9 = model3.wv.most_similar(\"war\")\n",
        "print(model3_result9)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('wars', 0.7616546750068665), ('warring', 0.6635650396347046), ('battle', 0.6515286564826965), ('warred', 0.6063735485076904), ('conflicts', 0.5463763475418091), ('summaries', 0.5361846685409546), ('thon', 0.5360012650489807), ('invasion', 0.5324710011482239), ('army', 0.5272731781005859), ('summary', 0.5255724787712097)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Trtw3KqJrRj"
      },
      "source": [
        "from gensim.models import KeyedVectors\n",
        "model3.wv.save_word2vec_format('eng3_w2v') # 모델 저장\n",
        "loaded_model3 = KeyedVectors.load_word2vec_format(\"eng3_w2v\") # 모델 로드"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EljQDJE1AXC5"
      },
      "source": [
        "# 4.GloVe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRiykOIQ21jP"
      },
      "source": [
        "GloVe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhgfgmlm23X1",
        "outputId": "b545de51-fe5f-4564-fa99-4a898bdb5e44"
      },
      "source": [
        "!pip install glove_python_binary"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting glove_python_binary\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cc/11/d8510a80110f736822856db566341dd2e1e7c3af536f77e409a6c09e0c22/glove_python_binary-0.2.0-cp37-cp37m-manylinux1_x86_64.whl (948kB)\n",
            "\u001b[K     |████████████████████████████████| 952kB 7.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from glove_python_binary) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from glove_python_binary) (1.4.1)\n",
            "Installing collected packages: glove-python-binary\n",
            "Successfully installed glove-python-binary-0.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCDb8Unz28oq"
      },
      "source": [
        "from glove import Corpus, Glove"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOMTk_lAXuDd",
        "outputId": "0dcd4f78-7a99-43a6-aa5d-d86da3a18fca"
      },
      "source": [
        "corpus = Corpus() \n",
        "corpus.fit(sentences_train, window=5)\n",
        "# 훈련 데이터로부터 GloVe에서 사용할 동시 등장 행렬 생성\n",
        "\n",
        "glove = Glove(no_components=100, learning_rate=0.05)\n",
        "glove.fit(corpus.matrix, epochs=20, no_threads=4, verbose=True)\n",
        "glove.add_dictionary(corpus.dictionary)\n",
        "# 학습에 이용할 쓰레드의 개수는 4로 설정, 에포크는 20."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Performing 20 training epochs with 4 threads\n",
            "Epoch 0\n",
            "Epoch 1\n",
            "Epoch 2\n",
            "Epoch 3\n",
            "Epoch 4\n",
            "Epoch 5\n",
            "Epoch 6\n",
            "Epoch 7\n",
            "Epoch 8\n",
            "Epoch 9\n",
            "Epoch 10\n",
            "Epoch 11\n",
            "Epoch 12\n",
            "Epoch 13\n",
            "Epoch 14\n",
            "Epoch 15\n",
            "Epoch 16\n",
            "Epoch 17\n",
            "Epoch 18\n",
            "Epoch 19\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wW21YelAXz0S",
        "outputId": "c441d66e-3272-415e-cfb7-2232e83ec2dc"
      },
      "source": [
        "model10=glove.most_similar(\"good\")\n",
        "print(model10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('faith', 0.8247972873627928), ('job', 0.8120741715616953), ('luck', 0.8112106903027019), ('idea', 0.7627503518200783)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGxSv_QzZchL",
        "outputId": "45fdea6d-e53a-47b5-fa0a-dbdbd6d9660c"
      },
      "source": [
        "model11=glove.most_similar(\"war\")\n",
        "print(model11)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('2008georgia', 0.8764123279736562), ('ii', 0.8563759568104301), ('criminalwar', 0.8475772772073239), ('cold', 0.8221995082170612)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNIsV5V_Zc5V",
        "outputId": "4d470086-18ea-4c76-8553-c4ebc9f5e8d0"
      },
      "source": [
        "model12=glove.most_similar(\"fuck\")\n",
        "print(model12)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('fuckity', 0.9545293112568916), ('uuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuu', 0.9294739596081624), ('misterwiki', 0.9209461940470126), ('yourselfgo', 0.9129870378639713)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmX2i0jM5Zgl"
      },
      "source": [
        "FastText"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2Z2JpeX5b_Z"
      },
      "source": [
        "from gensim.models import FastText\n",
        "ft_model = FastText(sentences_train, size=100, window=5, min_count=5, workers=4, sg=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QukSktkq5ceH",
        "outputId": "7813a270-a945-493b-9960-af956f9d6645"
      },
      "source": [
        "model2_result = ft_model.wv.most_similar(\"explanation\")\n",
        "print(model2_result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('explanations', 0.9122016429901123), ('explanatory', 0.888404369354248), ('explaning', 0.8416481018066406), ('justification', 0.7587119340896606), ('explaination', 0.7326990365982056), ('alteration', 0.7067852020263672), ('edification', 0.7040871381759644), ('ration', 0.6963322758674622), ('explination', 0.6893163919448853), ('justifications', 0.6858721971511841)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FtHV9m3iJWU_",
        "outputId": "e06e5844-083b-4d84-b3bf-317257756fe0"
      },
      "source": [
        "model3_result = ft_model.wv.most_similar(\"war\")\n",
        "print(model3_result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('wars', 0.7554676532745361), ('warzone', 0.7221353650093079), ('warsaw', 0.6897923946380615), ('battle', 0.6818721294403076), ('wart', 0.6776053309440613), ('wwii', 0.6757681369781494), ('warring', 0.6752650737762451), ('wartime', 0.6540999412536621), ('battlefield', 0.6531223058700562), ('ww1', 0.6527427434921265)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEjG69I9xoU-"
      },
      "source": [
        "### 4. 모델"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UpWn5f3mxyHM"
      },
      "source": [
        "##### 1. BiLSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXkK96CDOzjU",
        "outputId": "47899aee-af1a-4c0b-ebf7-c2df2dc4b70e"
      },
      "source": [
        "input = Input(shape = (max_len,))\n",
        "layer = Embedding(num_words,emb_size)(input) #num_words의 단어를 emb_size로 벡터화\n",
        "layer = Bidirectional(LSTM(50,return_sequences=True,recurrent_dropout=0.15))(layer) #return_sequences : 레이어를 여러 개 쌓아 올릴 때\n",
        "# recurrent_dropout : 현재 Input에 영향을 받는 Parameter에만 Dropout을 적용하는 것\n",
        "layer = GlobalMaxPool1D()(layer)\n",
        "layer = Dropout(0.2)(layer)\n",
        "layer = Dense(50,activation = 'relu')(layer)\n",
        "layer = Dropout(0.2)(layer)\n",
        "layer = Dense(6,activation = 'sigmoid')(layer)\n",
        "model = Model(inputs = input, outputs=layer)\n",
        "model.compile(loss = 'binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 150)]             0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, 150, 120)          2400000   \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 150, 100)          68400     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_1 (Glob (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 50)                5050      \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 6)                 306       \n",
            "=================================================================\n",
            "Total params: 2,473,756\n",
            "Trainable params: 2,473,756\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPeZWcilQ1Cd"
      },
      "source": [
        "file_path = '{epoch:02d}-{val_loss:.5f}.h5'\n",
        "checkpoint = ModelCheckpoint(file_path,monitor='val_loss',verbose = 1, save_best_only=True)\n",
        "early_stop = EarlyStopping(monitor='val_loss',patience=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlyNSXFsRlPZ",
        "outputId": "27a8d1f8-55a2-4541-fe04-244bc3f2b8d2"
      },
      "source": [
        "hist = model.fit(X,y,batch_size=32, epochs=2, validation_split = 0.2, callbacks= [checkpoint,early_stop])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-4162adcd0c55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mearly_stop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7POVmTgR0fU"
      },
      "source": [
        "model.save('toxic1_model1',save_format='tf')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZCagn0ZyRC1"
      },
      "source": [
        "##### 2. GRU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30CbiIhg9mKV"
      },
      "source": [
        "def bm_gru(num_words, emb):\n",
        "    input = Input(shape=(max_len,))\n",
        "    x = Embedding(num_words, emb)(input)\n",
        "    x = GRU(128)(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "    x = Dense(50,activation = 'relu')(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "    output = Dense(6,activation = 'sigmoid')(x)\n",
        "\n",
        "    model = Model(inputs = input, outputs=output)\n",
        "\n",
        "    model.compile(loss = 'binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "    model.summary()\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Gy45szY-X34"
      },
      "source": [
        "model_gru = bm_gru(num_words, 128)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mad-DEF-rIe"
      },
      "source": [
        "hist = model_gru.fit(train_x, train_y, batch_size=32, epochs=5, validation_split = 0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7K1WPrfrZw5"
      },
      "source": [
        "acc_loss_plot(hist)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SpfLwbZAT5z"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}